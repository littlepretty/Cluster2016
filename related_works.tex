\section{Related Works}
\label{Sec:RelatedWorks}

I/O contention in HPC systems draws a lot of attension in the community 
because it is one of the major culprits for parallel applications’ performance variability.
Hashimoto et al. evaluate the performance variability of each job 
when they run concurrently on the same physical computing server. 
They identify that network I/O sharing introduces most of 
the performance degradation \cite{hashimoto:ICNC:2012}.  
Dorier et al. analyze the I/O interference between two applications. 
They make quantified study about performance improvement obtained 
by interrupting or delaying either one in order to avoid I/O contention \cite{dorier:IPDPS:2014}.
Yildiz et al. \cite{yildiz:IPDPS:2016} explore the various root causes 
of I/O interference in HPC storage systems. 
They find that in many situations interference is a result of bad flow control in the I/O path, 
rather than being caused by some single bottleneck in one of its components.

The solutions for alleviate I/O contention between concurrently 
running jobs have been proposed in recent works.
Lofstead et al. schedule each application’s I/O request individually without 
a global view from system’s perspective \cite{lofstead:sc:2010}. 
Their solutions require supports from specific I/O management 
in the system level for better results. 
Zhou et al. design a new I/O aware batch scheduler to address the I/O 
contention problem at batch scheduling level \cite{zhou:Cluster:2015}. 
The new scheduler schedules and coordinates the 
I/O requrests without hurting the fairness across applications. 
Liu et al. proposed to move many file handling to the I/O nodes to 
ameliorate the I/O pressure from the massive number of compute nodes\cite{Liu:MSST:2012}.
Slurm developed a new module for its batch scheduler that could allocate burst buffer 
resource to submitted user jobs. With pre-allocated burst buffer, 
I/O performance of user job can be greatly improved \cite{SlurmBBGuide}.
However, the policy they used for resource allocation is in first-come, first-serve manner without any optimizatoin. 

Our work is different from the existing research in the following ways. 
We target on intellegently assigning burst buffer as a new system resuorces to user jobs
upon their submission.
In our scheduling model, users are encouraged to provide burst buffer demand
when making job submission.
Based on the possible useage cases of burst buffer, 
the execution of user job is modeled into three phases. 
The job could requrest different resources in each phase.
We propose a new batch scheduler with burst buffer awareness, Cerberus, 
making scheduling decisions for jobs in each specific phase.
Cerberus is also integrated with different optimizatoin algorithms 
for the objectives of maximizing resource utilization and system throughput.


% \cite{SlurmBBGuide}


